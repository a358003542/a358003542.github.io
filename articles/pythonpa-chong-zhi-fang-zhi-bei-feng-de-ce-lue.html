<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="baidu-site-verification" content="D4VqC4HppC"/>
    <meta name="msvalidate.01" content="55CB117A61A6F8286173763FB18D9625"/>

        <meta name="author" content="cdwanze"/>
        <meta name="copyright" content="cdwanze"/>

        <meta property="og:type" content="article"/>
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", python爬虫, " />

<meta property="og:title" content="python爬虫之-防止被封的策略 "/>
<meta property="og:url" content="/articles/pythonpa-chong-zhi-fang-zhi-bei-feng-de-ce-lue.html" />
<meta property="og:description" content="防止被封的首要策略就是尽量的为别人的服务器多考虑下，让自己写的爬虫少请求，每次请求都是有效的核心请求获取最核心的数据，不管是刷页面还是刷ajax，多次请求之间应该设置一个停顿时间。 time.sleep(3) 在上面的首要原则的基础上，下面介绍的很多实战技巧，其实都符合一个大的原则：尽可能地让你的爬虫和人浏览网页没有区别。 http请求头调整 user-agent 设置，而且时不时的切换下。 虽然目前还没有遇到，不过我推测可能 Referrer 这个header在某些场景下是有些文章的。 还有 Accept-Language 也可能有用。 Cookies 有些情况下cookies的正常获取需要javascript的支持。cookies总的原则是第一次请求获取到cookies，然后后面的很多次请求都使用这个cookies即可。 不过反爬虫cookies一般都会有个时间限制，一个简单的做法就是这边也设置个时间，定时获取最新的cookies或者，一定请求量之后再获取一个新的cookies。 具体使用 scrapy-splash 了解下。 表单陷阱 有的表单里面有： &lt;input type=&#34;hidden&#34; ... 我们要记住人如果在页面上点击，这个没有显示的字段的值也会一并送过去，而他们服务器那边会根据这个值可能是个加密的某个值来判断这个请求是人点的还是爬虫行为。 最好的策略是先把整个表单内容爬过来，收集好之后再发送表单请求。 和上面的情况相反，还有一种情况，页面表单发送可能有特别的处理，某些表单字段，不管用户看得见看不见，你都不能发送过去 …" />
<meta property="og:site_name" content="cdwanze的博文" />
<meta property="og:article:author" content="cdwanze" />
<meta property="og:article:published_time" content="2018-06-14T00:00:00+08:00" />
<meta name="twitter:title" content="python爬虫之-防止被封的策略 ">
<meta name="twitter:description" content="防止被封的首要策略就是尽量的为别人的服务器多考虑下，让自己写的爬虫少请求，每次请求都是有效的核心请求获取最核心的数据，不管是刷页面还是刷ajax，多次请求之间应该设置一个停顿时间。 time.sleep(3) 在上面的首要原则的基础上，下面介绍的很多实战技巧，其实都符合一个大的原则：尽可能地让你的爬虫和人浏览网页没有区别。 http请求头调整 user-agent 设置，而且时不时的切换下。 虽然目前还没有遇到，不过我推测可能 Referrer 这个header在某些场景下是有些文章的。 还有 Accept-Language 也可能有用。 Cookies 有些情况下cookies的正常获取需要javascript的支持。cookies总的原则是第一次请求获取到cookies，然后后面的很多次请求都使用这个cookies即可。 不过反爬虫cookies一般都会有个时间限制，一个简单的做法就是这边也设置个时间，定时获取最新的cookies或者，一定请求量之后再获取一个新的cookies。 具体使用 scrapy-splash 了解下。 表单陷阱 有的表单里面有： &lt;input type=&#34;hidden&#34; ... 我们要记住人如果在页面上点击，这个没有显示的字段的值也会一并送过去，而他们服务器那边会根据这个值可能是个加密的某个值来判断这个请求是人点的还是爬虫行为。 最好的策略是先把整个表单内容爬过来，收集好之后再发送表单请求。 和上面的情况相反，还有一种情况，页面表单发送可能有特别的处理，某些表单字段，不管用户看得见看不见，你都不能发送过去 …">

    <title>
python爬虫之-防止被封的策略  · cdwanze的博文
</title>


        <link href="/theme/css/font-awesome.css" rel="stylesheet"
              media="screen">
        <link href="/theme/css/bootstrap.min.css" rel="stylesheet"
              media="screen">

            <link rel="stylesheet" type="text/css"
                  href="/theme/css/pygments.css" media="screen">
            <link rel="stylesheet" type="text/css"
                  href="/theme/css/elegant.css" media="screen">
            <link rel="stylesheet" type="text/css"
                  href="/theme/css/custom.css" media="screen">






</head>
<body>

<nav class="navbar">
    <div class="navbar navbar-default" role="navigation">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed"
                    data-toggle="collapse" data-target=".navbar-collapse"
                    aria-expanded="false">
                <span class="sr-only">Navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <a class="navbar-brand" href="/"><span
                    class=site-name>网站首页</span></a>
        </div>


        <div class="navbar-collapse collapse">
            <form action="/search.html"
                  onsubmit="return validateForm(this.elements['q'].value);"
                  class="navbar-form navbar-left">
                <div class="form-group">
                    <input type="text" name="q" id="tipue_search_input"
                           class="form-control" placeholder="Search..."
                           style="width:430px;">
                </div>
                <button class="btn btn-default" type="submit">搜索</button>
            </form>


            <ul class="nav navbar-nav nav-pills navbar-right">
                <li >
                    <a href="">博文首页</a></li>

                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle"
                           data-toggle="dropdown" role="button"
                           aria-haspopup="true" aria-expanded="false">查找文章<span
                                class="caret"></span></a>
                        <ul class="dropdown-menu">
                            <li><a class="slowscroll" href="/categories.html">按分类</a>
                            </li>
                            <li><a class="slowscroll" href="/tags.html">按标签</a>
                            </li>
                        </ul>
                    </li>


                        <li >
                            <a href="/guan-yu-ben-wang-zhan.html">关于本网站</a>
                        </li>
                        <li >
                            <a href="/gong-gao.html">公告</a>
                        </li>
            </ul>


        </div>
    </div>
</nav>


<div class="container-fluid">
    <div class="col-md-1 col-md-1-left"></div>
    <div class="col-md-10">
<article>
<div class="row">
    <header class="page-header col-md-10 col-md-offset-2">
    <h1><a href="/articles/pythonpa-chong-zhi-fang-zhi-bei-feng-de-ce-lue.html"> python爬虫之-防止被封的策略  </a></h1>
    </header>
</div>

<div class="row">
    <div class="col-md-2 table-of-content">
        <nav>
        <h4>目录</h4>
        <div class="toc">
<ul>
<li><a href="#http">http请求头调整</a></li>
<li><a href="#cookies">Cookies</a></li>
<li><a href="#_1">表单陷阱</a></li>
<li><a href="#403-forbidden">403 forbidden</a></li>
<li><a href="#_2">参考资料</a></li>
</ul>
</div>
        </nav>
    </div>
    <div class="col-md-8 article-content">

            
            
<p>防止被封的首要策略就是尽量的为别人的服务器多考虑下，让自己写的爬虫少请求，每次请求都是有效的核心请求获取最核心的数据，不管是刷页面还是刷ajax，多次请求之间应该设置一个停顿时间。</p>
<div class="highlight"><pre><span></span>time.sleep(3)
</pre></div>
<p>在上面的首要原则的基础上，下面介绍的很多实战技巧，其实都符合一个大的原则：尽可能地让你的爬虫和人浏览网页没有区别。</p>
<h2 id="http">http请求头调整</h2>
<p>user-agent 设置，而且时不时的切换下。</p>
<p>虽然目前还没有遇到，不过我推测可能 Referrer 这个header在某些场景下是有些文章的。</p>
<p>还有 Accept-Language 也可能有用。</p>
<h2 id="cookies">Cookies</h2>
<p>有些情况下cookies的正常获取需要javascript的支持。cookies总的原则是第一次请求获取到cookies，然后后面的很多次请求都使用这个cookies即可。</p>
<p>不过反爬虫cookies一般都会有个时间限制，一个简单的做法就是这边也设置个时间，定时获取最新的cookies或者，一定请求量之后再获取一个新的cookies。</p>
<p>具体使用 scrapy-splash 了解下。</p>
<h2 id="_1">表单陷阱</h2>
<p>有的表单里面有：</p>
<div class="highlight"><pre><span></span>&lt;input type="hidden" ...
</pre></div>
<p>我们要记住人如果在页面上点击，这个没有显示的字段的值也会一并送过去，而他们服务器那边会根据这个值可能是个加密的某个值来判断这个请求是人点的还是爬虫行为。</p>
<p>最好的策略是先把整个表单内容爬过来，收集好之后再发送表单请求。</p>
<p>和上面的情况相反，还有一种情况，页面表单发送可能有特别的处理，某些表单字段，不管用户看得见看不见，你都不能发送过去，只要发送过去就会被毙掉。</p>
<p>继续上面的表单陷阱，某些css也会动态将某个input 属于hidden属性，这个需要好好分析下。</p>
<h2 id="403-forbidden">403 forbidden</h2>
<p>这极有可能是你的爬虫被封了。</p>
<h2 id="_2">参考资料</h2>
<ul>
<li>web scraping with python   writing by Ryan Mitchell</li>
</ul>
            
            
            <hr/>

        </div>
        <section>
        <div class="col-md-2" style="float:right;font-size:0.9em;">
            <h4>首发于：</h4>
            <time pubdate="pubdate" datetime="2018-06-14T00:00:00+08:00">2018年 6月 14日 </time>
            <h4>分类：</h4>
            <a class="category-link" href="/categories.html#pythonpa-chong-ref">python爬虫</a>
        </div>
        </section>
</div>
</article>
    </div>
    <div class="col-md-1"></div>

</div>


<div id="push"></div>


<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a> and updated by <a href="http://www.cdwanze.work" title="cdwanze Home Page">cdwanze</a></li>
    </ul>
</div>
</footer>

        <script src="/theme/js/jquery.min.js"></script>
    <script src="/theme/js/bootstrap.min.js"></script>
    <script>
        function validateForm(query) {
            return (query.length > 0);
        }
    </script>

    <script>
        function adjust_search_width() {
            var w = document.documentElement.clientWidth;
            if ((w > 755) && (w < 975)) {
                plus_width = w - 755;
                $('.navbar-form .form-control').outerWidth(210 + plus_width);
            } else if (w >= 975) {
                $('.navbar-form .form-control').outerWidth(210 + 220);
            } else if (w <= 755) {
                $('.navbar-form .form-control').css('width', '100%')
            }
        }

        $(document).ready(function () {
            adjust_search_width();
        });

        window.onresize = function () {
            adjust_search_width();
        }

    </script>


    



</body>
</html>