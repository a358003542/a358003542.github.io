<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="msvalidate.01" content="55CB117A61A6F8286173763FB18D9625"/>

        <meta name="author" content="wanze"/>
        <meta name="copyright" content="wanze"/>

        <meta name="description"
              content="简介 BeautifulSoup模块在python网页分析这一块是很有名的一个模块，其确实让网页分析任务变得轻松而easy了。本文将对bs4模块进行简单的介绍，更多细节请参看 官方文档 。 安装 安装就简单用pip命令安装之: sudo pip install beautifulsoup 第一个例子 然后在使用上因为python2和python3的urllib相关改动很大，加上urllib在使用上不是很友好，强烈推荐大家直接用requests模块来进行相关操作。然后beautifulsoup的引入语句一般如下所示: from bs4 import BeautifulSoup 最简单的和requests的组合使用如下所示: import requests from bs4 import BeautifulSoup res = requests.get(&#34;http://www.pythonscraping.com/exercises/exercise1.html&#34;) soup = BeautifulSoup(res.text) print(soup.title) 在上面soup.title返回的是一个标签对象。然后标签对象里面如果有标签的话又可以继续点号索引标签: &gt;&gt;&gt; soup.body …
"/>

        <meta property="og:type" content="article"/>
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="python, python_companion, " />

<meta property="og:title" content="beautifulsoup模块 "/>
<meta property="og:url" content="https://a358003542.github.io/articles/beautifulsoup-module.html" />
<meta property="og:description" content="简介 BeautifulSoup模块在python网页分析这一块是很有名的一个模块，其确实让网页分析任务变得轻松而easy了。本文将对bs4模块进行简单的介绍，更多细节请参看 官方文档 。 安装 安装就简单用pip命令安装之: sudo pip install beautifulsoup 第一个例子 然后在使用上因为python2和python3的urllib相关改动很大，加上urllib在使用上不是很友好，强烈推荐大家直接用requests模块来进行相关操作。然后beautifulsoup的引入语句一般如下所示: from bs4 import BeautifulSoup 最简单的和requests的组合使用如下所示: import requests from bs4 import BeautifulSoup res = requests.get(&#34;http://www.pythonscraping.com/exercises/exercise1.html&#34;) soup = BeautifulSoup(res.text) print(soup.title) 在上面soup.title返回的是一个标签对象。然后标签对象里面如果有标签的话又可以继续点号索引标签: &gt;&gt;&gt; soup.body …" />
<meta property="og:site_name" content="wanze的博文" />
<meta property="og:article:author" content="wanze" />
<meta property="og:article:published_time" content="2020-03-07T00:14:15.887446+08:00" />
<meta name="twitter:title" content="beautifulsoup模块 ">
<meta name="twitter:description" content="简介 BeautifulSoup模块在python网页分析这一块是很有名的一个模块，其确实让网页分析任务变得轻松而easy了。本文将对bs4模块进行简单的介绍，更多细节请参看 官方文档 。 安装 安装就简单用pip命令安装之: sudo pip install beautifulsoup 第一个例子 然后在使用上因为python2和python3的urllib相关改动很大，加上urllib在使用上不是很友好，强烈推荐大家直接用requests模块来进行相关操作。然后beautifulsoup的引入语句一般如下所示: from bs4 import BeautifulSoup 最简单的和requests的组合使用如下所示: import requests from bs4 import BeautifulSoup res = requests.get(&#34;http://www.pythonscraping.com/exercises/exercise1.html&#34;) soup = BeautifulSoup(res.text) print(soup.title) 在上面soup.title返回的是一个标签对象。然后标签对象里面如果有标签的话又可以继续点号索引标签: &gt;&gt;&gt; soup.body …">


    <title>beautifulsoup模块  · wanze的博文
</title>

        <link href="https://a358003542.github.io/theme/css/font-awesome.css" rel="stylesheet"
              media="screen">
        <link href="https://a358003542.github.io/theme/css/bootstrap.min.css" rel="stylesheet"
              media="screen">

        <link rel="stylesheet" type="text/css"
                  href="https://a358003542.github.io/theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css"
                  href="https://a358003542.github.io/theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css"
                  href="https://a358003542.github.io/theme/css/base.css" media="screen">




</head>
<body>

<nav class="navbar">
    <div class="navbar navbar-default" role="navigation">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed"
                    data-toggle="collapse" data-target=".navbar-collapse"
                    aria-expanded="false">
                <span class="sr-only">Navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <a class="navbar-brand" href="https://a358003542.github.io/"><span
                    class=site-name>网站首页</span></a>
        </div>


        <div class="navbar-collapse collapse">
            <form action="https://a358003542.github.io/search.html"
                  onsubmit="return validateForm(this.elements['q'].value);"
                  class="navbar-form navbar-left">
                <div class="form-group">
                    <input type="text" name="q" id="tipue_search_input"
                           class="form-control" placeholder="Search..."
                           style="width:430px;">
                </div>
                <button class="btn btn-default" type="submit">搜索</button>
            </form>


            <ul class="nav navbar-nav nav-pills navbar-right">
                <li >
                    <a  href="/archives.html">所有文章</a></li>

                <li ><a href="/categories.html">文章分类</a></li>
                <li ><a href="/tags.html">文章标签</a></li>


                        <li >
                            <a href="https://a358003542.github.io/about.html">关于本网站</a>
                        </li>
            </ul>


        </div>
    </div>
</nav>


<div class="container-fluid">
    <div class="col-md-1 col-md-1-left"></div>
    <div class="col-md-10">
<article>
<div class="row">
    <header class="page-header col-md-10 col-md-offset-2">
    <h1><a href="https://a358003542.github.io/articles/beautifulsoup-module.html"> beautifulsoup模块  </a></h1>
    </header>
</div>

<div class="row">
    <div class="col-md-2 table-of-content">
        <nav>
        <h4>目录</h4>
        <div class="toc">
<ul>
<li><a href="#_1">简介</a><ul>
<li><a href="#_2">安装</a></li>
<li><a href="#_3">第一个例子</a></li>
</ul>
</li>
<li><a href="#find">find方法</a><ul>
<li><a href="#_4">过滤器</a></li>
<li><a href="#class95">class_参量</a></li>
<li><a href="#id">id参量</a></li>
<li><a href="#text">text参量</a></li>
<li><a href="#keywords">其他keywords</a></li>
<li><a href="#recursive">recursive参量</a></li>
<li><a href="#limit">limit参量</a></li>
</ul>
</li>
<li><a href="#find95all">find_all方法</a></li>
<li><a href="#_5">标签元素对象</a></li>
<li><a href="#_6">基于某个标签的附加查找</a><ul>
<li><a href="#_7">平行级别上下标签</a><ul>
<li><a href="#_8">平行级别下标签</a></li>
<li><a href="#_9">平行级别上标签</a></li>
</ul>
</li>
<li><a href="#_10">非平行级别上下标签</a></li>
</ul>
</li>
<li><a href="#select">select方法</a><ul>
<li><a href="#_11">移除某个标签</a></li>
</ul>
</li>
<li><a href="#_12">解析部分文档来提升效率</a></li>
</ul>
</div>
        </nav>
    </div>
    <div class="col-md-8 article-content">

            
            
<h1 id="_1">简介</h1>
<p>BeautifulSoup模块在python网页分析这一块是很有名的一个模块，其确实让网页分析任务变得轻松而easy了。本文将对bs4模块进行简单的介绍，更多细节请参看 <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">官方文档</a> 。</p>
<h2 id="_2">安装</h2>
<p>安装就简单用pip命令安装之:</p>
<div class="highlight"><pre><span></span>sudo pip install beautifulsoup
</pre></div>
<h2 id="_3">第一个例子</h2>
<p>然后在使用上因为python2和python3的urllib相关改动很大，加上urllib在使用上不是很友好，强烈推荐大家直接用requests模块来进行相关操作。然后beautifulsoup的引入语句一般如下所示:</p>
<div class="highlight"><pre><span></span>from bs4 import BeautifulSoup
</pre></div>
<p>最简单的和requests的组合使用如下所示:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"http://www.pythonscraping.com/exercises/exercise1.html"</span><span class="p">)</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">title</span><span class="p">)</span>
</pre></div>
<p>在上面soup.title返回的是一个标签对象。然后标签对象里面如果有标签的话又可以继续点号索引标签:</p>
<div class="highlight"><pre><span></span>&gt;&gt;&gt; soup.body.h1
&lt;h1&gt;An Interesting Title&lt;/h1&gt;
</pre></div>
<p>这时读者一定在想，文档里面相同的p标签有很多，soup会返回什么呢？</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"http://www.crummy.com/software/BeautifulSoup/bs4/doc/"</span><span class="p">)</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
</pre></div>
<p>我们看到soup返回的是第一个p标签，这可以看作下面要讲的find方法的简化css索引形式。</p>
<h1 id="find">find方法</h1>
<p>如下所示最简单的find定位实际上就类似于 <code>soup.p</code> 的用法。但find方法里面有更丰富的内容。</p>
<div class="highlight"><pre><span></span>&gt;&gt;&gt; soup.find('p')
&lt;p&gt;&lt;a class="reference external" href="http://www.crummy.com/software/BeautifulSoup/"&gt;Beautiful Soup&lt;/a&gt; is a
Python library for pulling data out of HTML and XML files. It works
with your favorite parser to provide idiomatic ways of navigating,
searching, and modifying the parse tree. It commonly saves programmers
hours or days of work.&lt;/p&gt;
</pre></div>
<p>find方法如果找不到就返回None，找到则返回目标标签元素。</p>
<div class="highlight"><pre><span></span>&gt;&gt;&gt; soup.test is None
True
</pre></div>
<h2 id="_4">过滤器</h2>
<p>find方法最常用的形式是接受一个参数，这个参数叫做什么过滤器参数。过滤器可以是字符串或正则表达式或列表组成，其中列表里面的元素基于前面谈及的字符串或正则表达式，然后组成或逻辑，只要符合一个匹配条件就认为是匹配的。</p>
<p>第一个参量也就是name参量是针对tag的操作，通常简单的字符串就够用了，如果是正则表达式的话，则是 <code>re.compile("^b")</code> 这样的形式，然后其内是通过正则表达式的 <strong>match</strong> 方法来完成的（稍作测试，我觉得应该对应的re.search。）。</p>
<p>最后要额外一提的就是过滤器 <code>True</code> ，其会匹配任何值，比如说 <code>id=True</code> ，将会匹配所有有id属性的标签。</p>
<h2 id="class95">class_参量</h2>
<p>你可以通过 <code>class_=</code> 来过滤标签的class属性，注意为了和python的class关键词区分，后面加上了一个下划线，同样是接受一个过滤器。</p>
<h2 id="">id参量</h2>
<p>你可以通过 <code>id=</code> 来具体定位网页中的某个id，也是接受一个过滤器。</p>
<h2 id="text">text参量</h2>
<p>对网页各个标签内的字符串进行过滤操作，前面提及的过滤器一样都可以用，不过字符串是精确匹配的我估计用得会比较少。尽可能地用正则表达式。然后如果单独使用text参量</p>
<div class="highlight"><pre><span></span>soup.find_all(text=re.compile('name'))
</pre></div>
<p>标签里面的字符串也会被搜索，而且返回也不一定是标准的标签元素对象，这很不好。推荐采用如下形式:</p>
<div class="highlight"><pre><span></span>soup.find_all(True,text=re.compile('name'))
</pre></div>
<p>这样返回的必定是标签元素，而且text里面必定只搜索标签的text字符串内容，这更易于人们的理解。</p>
<p>然后搜索完之后你可能定位到的是某个小标签，比如 <code>&lt;b&gt;</code> 之类的，然后你可以对目标标签元素使用 <code>.parent</code> ，则将返回更高一级的标签元素，这有时会很有用的:</p>
<div class="highlight"><pre><span></span>soup.find_all(True,text=re.compile('name'))[-1].parent
</pre></div>
<h2 id="keywords">其他keywords</h2>
<p>其他标签的各个属性都可以类似上面的作为关键词加上过滤器来搜索。比如</p>
<div class="highlight"><pre><span></span>oup.find_all(href=re.compile("elsie"))
</pre></div>
<h2 id="recursive">recursive参量</h2>
<p>recursive默认是True，也就是检索当前tag的所有子孙节点，如果只想搜索当前tag的第一级子节点，则使用 <code>recursive=False</code> 。</p>
<h2 id="limit">limit参量</h2>
<p>这个只对find_all才有意义，确定返回几个元素。</p>
<h1 id="find95all">find_all方法</h1>
<p>find_all和find方法API类似，除了find_all返回的是一系列匹配的标签元素的列表。在这里顺便提一下，find方法和find_all方法可以接受多个参数作为限定，这些限定条件可以看作逻辑与关系。</p>
<h1 id="_5">标签元素对象</h1>
<p>具体标签元素的使用见下面例子:</p>
<div class="highlight"><pre><span></span>&gt;&gt;&gt; import re
&gt;&gt;&gt; soup.find(True,text=re.compile("sister"))
&lt;span class="s"&gt;&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were&lt;/span&gt;
&gt;&gt;&gt; thetag = soup.find(True,text=re.compile("sister"))
&gt;&gt;&gt; thetag.name
'span'
&gt;&gt;&gt; thetag.text
'&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were'
&gt;&gt;&gt; thetag.string
'&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were'
&gt;&gt;&gt; type(thetag.string)
&lt;class 'bs4.element.NavigableString'&gt;
&gt;&gt;&gt; type(thetag.text)
&lt;class 'str'&gt;
&gt;&gt;&gt; thetag['class']
['s']
</pre></div>
<ul>
<li><strong>name:</strong> 标签对象的标签名字</li>
<li><strong>string:</strong> 返回NavigableString对象，这里暂时先略过讨论。</li>
<li><strong>text:</strong> 返回标签所包含的文本对象。</li>
<li><strong>get_text():</strong> 从最新的bs4文档来看，官方文档推荐tag获取其内文本内容都用 <code>get_text</code> 方法，而不要使用上面的 <code>thetag.text</code> 这种形式了。</li>
<li><strong>['class']:</strong> 属性值索引，上面的"class"属性具体返回的是一个列表，叫做什么多值属性。</li>
</ul>
<h1 id="_6">基于某个标签的附加查找</h1>
<p>我们通过 <code>find</code> 或 <code>find_all</code> 能够找到某个或某些标签对象了，然后bs4还给标签对象加上了一些辅助查找方法，基于这个标签对象来进一步查找，从而返回其他某个或某些标签对象。</p>
<h2 id="_7">平行级别上下标签</h2>
<p>这里所谓的平行级别上下标签是指如下面这个例子:</p>
<div class="highlight"><pre><span></span>&lt;html&gt;
    &lt;body&gt;
        &lt;a&gt;
            &lt;b&gt;text1&lt;/b&gt;
            &lt;c&gt;text2&lt;/c&gt;
        &lt;/a&gt;
        &lt;d&gt;test3&lt;/d&gt;
    &lt;/body&gt;
&lt;/html&gt;
</pre></div>
<p><b>标签和<c>标签就是一个html文档缩进深度，它们就属于一个层次的平行标签。而<a>和<d>也是属于平行标签，但<b>和<d>则不是。</d></b></d></a></c></b></p>
<h3 id="_8">平行级别下标签</h3>
<div class="highlight"><pre><span></span>find_next_sibling(name, attrs, string, **kwargs)
</pre></div>
<p>才外还有返回一些标签对象（对应find_all方法）的方法:</p>
<div class="highlight"><pre><span></span>find_next_siblings(name, attrs, string, limit, **kwargs)
</pre></div>
<p>比如上面的例子我们有:</p>
<div class="highlight"><pre><span></span>&gt;&gt;&gt; [ i for i in soup.a.next_siblings]
['\n', &lt;d&gt;test3&lt;/d&gt;, '\n']
&gt;&gt;&gt; [ i for i in soup.b.next_siblings]
['\n', &lt;c&gt;text2&lt;/c&gt;, '\n']
&gt;&gt;&gt;
</pre></div>
<p>这些方法的用法和前面谈及的 <code>find</code> 还有 <code>find_all</code> 类似，但多少有点令人沮丧的是，beautifulsoup受到换行符的干扰，在 <a href="https://stackoverflow.com/questions/23241641/how-to-ignore-empty-lines-while-using-next-sibling-in-beautifulsoup4-in-python">这篇网页</a> 中提到预处理网页将换行符都换成空格，然后将标签之间的各个空格符号都删除的解决方案，虽然不是很完美，但作为解决也是可以接受的，因为网络抓取实际上进来的网页简化预处理是必须要做的一步工作。</p>
<h3 id="_9">平行级别上标签</h3>
<p>平行级别上标签类似上面的描述，不过是往上走，这里就不赘述了。</p>
<div class="highlight"><pre><span></span>find_previous_sibling(name, attrs, string, **kwargs)
</pre></div>
<p>此外还有返回一些标签对象（对应find_all方法）的方法:</p>
<div class="highlight"><pre><span></span>find_previous_siblings(name, attrs, string, limit, **kwargs)
</pre></div>
<h2 id="_10">非平行级别上下标签</h2>
<p>find_parents(name, attrs, string, limit, **kwargs)
find_parent(name, attrs, string, **kwargs)</p>
<p>find_all_next(name, attrs, string, limit, **kwargs)
find_next(name, attrs, string, **kwargs)
find_all_previous(name, attrs, string, limit, **kwargs)
find_previous(name, attrs, string, **kwargs)
.contents and .children</p>
<h1 id="select">select方法</h1>
<p>select方法通过CSS选择器来进行标签元素的选择。原则上上面谈论的那些方法已经能够满足我们大部分的需求了，再加上专门针对某个个别网站的个别网页的css布局而进行抓取，这种抓取方法是很不灵活很有局限性的，所以select方法应该作为用户的最后备选方案。</p>
<h2 id="_11">移除某个标签</h2>
<div class="highlight"><pre><span></span>s = soup.find('sup')
s.extract()
</pre></div>
<h1 id="_12">解析部分文档来提升效率</h1>
<p>请看到下面这个函数，其用途是将整个webpage的所有a连接有href属性的链接收集起来。</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_webpage_links</span><span class="p">(</span><span class="n">html</span><span class="p">,</span><span class="n">baseurl</span><span class="p">):</span>
    <span class="sd">''' 刷本网页 a标签 有 href 属性的所有 links</span>
<span class="sd">    绝对化路径 去除fragment 返回字典值去重</span>
<span class="sd">    '''</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s1">'lxml'</span><span class="p">,</span> <span class="n">parse_only</span><span class="o">=</span><span class="n">SoupStrainer</span><span class="p">(</span><span class="s1">'a'</span><span class="p">))</span>
    <span class="n">links</span> <span class="o">=</span> <span class="p">[</span><span class="n">link</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'href'</span><span class="p">)</span> <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">'a'</span><span class="p">,</span><span class="n">href</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>
    <span class="n">links</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_absolute_url</span><span class="p">(</span><span class="n">baseurl</span><span class="p">,</span><span class="n">link</span><span class="p">)</span> <span class="k">for</span>  <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">]</span>
    <span class="n">links</span> <span class="o">=</span> <span class="p">[</span><span class="n">remove_url_fragment</span><span class="p">(</span><span class="n">link</span><span class="p">)</span> <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">set</span><span class="p">(</span><span class="n">links</span><span class="p">)</span>
</pre></div>
<p>其中:</p>
<div class="highlight"><pre><span></span>soup = BeautifulSoup(html, 'lxml', parse_only=SoupStrainer('a'))
</pre></div>
<p><code>parse_only</code> 参数用于控制BeautifulSoup一开始刷文档时创建标签元素对象的时候，就只刷某些标签而进行了过滤操作，从而大大节省了工作量。具体参数是创建一个 <code>SoupStrainer</code> 对象，其接受的过滤器语法和前面叙述的一样。</p>
            
            
            <hr/>

        </div>
        <section>
        <div class="col-md-2" style="float:right;font-size:0.9em;">
            <h4>首发于：</h4>
            <time pubdate="pubdate" datetime="2020-03-07T00:14:15.887446+08:00">2020年 3月 7日 </time>
            <h4>分类：</h4>
            <a class="category-link" href="https://a358003542.github.io/categories.html#python_companion-ref">python_companion</a>
            <h4>标签：</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://a358003542.github.io/tags.html#python-ref">python
                    <span>13</span>
</a></li>
            </ul>
        </div>
        </section>
</div>
</article>
    </div>
    <div class="col-md-1"></div>

</div>


<div id="push"></div>
<button id="gotop" type="button" class="btn btn-default">
    <span class="glyphicon glyphicon-arrow-up" aria-hidden="true"></span>
</button>

<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a> and updated by <a href="https://github.com/a358003542" title="wanze Home Page">wanze</a></li>
    </ul>
</div>
</footer>

        <script src="https://a358003542.github.io/theme/js/jquery.min.js"></script>
    <script src="https://a358003542.github.io/theme/js/bootstrap.min.js"></script>

    <script src="https://a358003542.github.io/theme/js/base.js"></script>

    


</body>
</html>