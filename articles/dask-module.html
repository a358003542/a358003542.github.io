<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="msvalidate.01" content="55CB117A61A6F8286173763FB18D9625"/>
    <meta name="google-site-verification" content="r5HyVvY-ZSgf7ctpcpK1aWIaEfKJ0dvAE3E9kW3vXgI" />
    <script data-ad-client="ca-pub-5644206261254049" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    
        <meta name="author" content="wanze"/>
        <meta name="copyright" content="wanze"/>

        <meta name="description"
              content="前言 总的说来对于python生态圈来说，大数据解决方案我是推荐dask多于pyspark。接触pyspark之后最大的痛苦就是，之前学习机器学习积累下来的numpy，pandas，sklearn的知识，全部不能继续使用了。而dask作为python的大数据解决方案，不说完全无缝对接，这也是不..."/>

        <meta property="og:type" content="article"/>
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", programming, " />

<meta property="og:title" content="dask模块 "/>
<meta property="og:url" content="https://a358003542.github.io/articles/dask-module.html" />
<meta property="og:description" content="前言 总的说来对于python生态圈来说，大数据解决方案我是推荐dask多于pyspark。接触pyspark之后最大的痛苦就是，之前学习机器学习积累下来的numpy，pandas，sklearn的知识，全部不能继续使用了。而dask作为python的大数据解决方案，不说完全无缝对接，这也是不..." />
<meta property="og:site_name" content="万泽的博客" />
<meta property="og:article:author" content="wanze" />
<meta property="og:article:published_time" content="2019-09-22T00:00:00+08:00" />
<meta name="twitter:title" content="dask模块 ">
<meta name="twitter:description" content="前言 总的说来对于python生态圈来说，大数据解决方案我是推荐dask多于pyspark。接触pyspark之后最大的痛苦就是，之前学习机器学习积累下来的numpy，pandas，sklearn的知识，全部不能继续使用了。而dask作为python的大数据解决方案，不说完全无缝对接，这也是不...">


    <title>dask模块  · 万泽的博客
</title>

        <link href="https://a358003542.github.io/theme/css/font-awesome.css" rel="stylesheet"
              media="screen">
        <link href="https://a358003542.github.io/theme/css/bootstrap.min.css" rel="stylesheet"
              media="screen">

        <link rel="stylesheet" type="text/css"
                  href="https://a358003542.github.io/theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css"
                  href="https://a358003542.github.io/theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css"
                  href="https://a358003542.github.io/theme/css/base.css" media="screen">




</head>
<body>

<nav class="navbar">
    <div class="navbar navbar-default" role="navigation">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed"
                    data-toggle="collapse" data-target=".navbar-collapse"
                    aria-expanded="false">
                <span class="sr-only">Navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <a class="navbar-brand" href="https://a358003542.github.io/"><span
                    class=site-name>网站首页</span></a>
        </div>


        <div class="navbar-collapse collapse">
            <form action="https://a358003542.github.io/search.html"
                  onsubmit="return validateForm(this.elements['q'].value);"
                  class="navbar-form navbar-left">
                <div class="form-group">
                    <input type="text" name="q" id="tipue_search_input"
                           class="form-control" placeholder="Search..."
                           style="width:430px;">
                </div>
                <button class="btn btn-default" type="submit">搜索</button>
            </form>


            <ul class="nav navbar-nav nav-pills navbar-right">
                <li >
                    <a  href="/archives.html">所有文章</a></li>

                <li ><a href="/categories.html">文章分类</a></li>
                <li ><a href="/tags.html">文章标签</a></li>


                        <li >
                            <a href="https://a358003542.github.io/about.html">关于本网站</a>
                        </li>
            </ul>


        </div>
    </div>
</nav>


<div class="container-fluid">
    <div class="col-md-1 col-md-1-left"></div>
    <div class="col-md-10">
<article>
<div class="row">
    <header class="page-header col-md-10 col-md-offset-2">
    <h1><a href="https://a358003542.github.io/articles/dask-module.html"> dask模块  </a></h1>
    </header>
</div>

<div class="row">
    <div class="col-md-2 table-of-content">
        <nav>
        <h4>目录</h4>
        <div class="toc">
<ul>
<li><a href="#_1">前言</a></li>
<li><a href="#hadoop">大数据hadoop简介</a></li>
<li><a href="#dask">dask简介</a></li>
<li><a href="#dask-yarn">dask-yarn</a><ul>
<li><a href="#worker">实际调整worker资源</a></li>
<li><a href="#_2">关闭应用释放资源</a></li>
<li><a href="#_3">强制关闭某个应用</a></li>
</ul>
</li>
<li><a href="#dataframe">dataframe最佳实践</a></li>
<li><a href="#dataframemap_partitions">dataframe的map_partitions 返回值</a></li>
<li><a href="#dask_1">dask单机版</a></li>
<li><a href="#_4">参考资料</a></li>
</ul>
</div>
        </nav>
    </div>
    <div class="col-md-8 article-content">

            
<h2 id="_1">前言</h2>
<p>总的说来对于python生态圈来说，大数据解决方案我是推荐dask多于pyspark。接触pyspark之后最大的痛苦就是，之前学习机器学习积累下来的numpy，pandas，sklearn的知识，全部不能继续使用了。而dask作为python的大数据解决方案，不说完全无缝对接，这也是不现实的，毕竟到了大数据那块，不说其他东西，就是你要应对的变量，也必然是惰性加载和惰性求值的，这也是一个区别点。但总的给我的感觉就是，作为python爱好者，之于大数据解决方案，dask真的用的很爽。</p>
<p>dask的官方文档写的很厚实，主要是这块东西也多。本文作者尽我所知简要地说下个人使用经验吧。其他深入研究还是要读者去研究 <a href="https://docs.dask.org/en/latest/">官方文档</a> 的。</p>
<h2 id="hadoop">大数据hadoop简介</h2>
<p>现在的hadoop2的架构大概如下所示：</p>
<p><img alt="img" src="https://a358003542.github.io/images/大数据/HADOOP.png"/></p>
<p>底层是hadoop分布式文件系统作为大数据的文件存储支持。HDFS的基本架构如下图所示：</p>
<p><img alt="img" src="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png"/></p>
<p>然后中层是YARN对计算资源进行调度分配。YARN的基本架构如下图所示：</p>
<p><img alt="img" src="http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif"/></p>
<p>如上图所示，Yarn有一个Scheduler，也就是Resource Manager 进行资源调度，然后还有很多 个worker，也就是Node Manager进行实际的应用计算任务。</p>
<p>而最高层MapReduce框架是分布式应用程序的一个支持性框架，现在Hadoop2可扩展性很好，dask，spark等这些框架都是可以运行在Yarn之上的。</p>
<h2 id="dask">dask简介</h2>
<p>dask主要由两部分组成：</p>
<ol>
<li>基于计算优化的动态调度 </li>
<li>大数据级别的集合</li>
</ol>
<p>简单来说就是dask基于python常见的那些数据类型概念，比如array，dataframe，进行大数据级别的集合扩展，其有很多个worker和一个scheduler，调度器主要负责计算调度，调度器面临的最小计算单位是所谓的partition，这个partition会分散在不同的worker中，具体这些worker会利用相同的python环境，来进行某些计算。</p>
<p>dask的安装就python模块来说不是难点所在，这一块难点主要在大数据环境的搭建上。如果你们大数据工作组已经将环境搭建好了，那么利用dask-yarn还是很容易进行dask的分布式任务的分发工作的。</p>
<h2 id="dask-yarn">dask-yarn</h2>
<p>dask连接yarn集群</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dask_yarn</span> <span class="kn">import</span> <span class="n">YarnCluster</span>
<span class="kn">from</span> <span class="nn">dask.distributed</span> <span class="kn">import</span> <span class="n">Client</span>

<span class="c1"># Create a cluster where each worker has two cores and eight GiB of memory</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">YarnCluster</span><span class="p">(</span><span class="n">environment</span> <span class="o">=</span> <span class="s1">'environment.tar.gz'</span><span class="p">,</span>
                      <span class="n">worker_vcores</span><span class="o">=</span><span class="n">w_cores</span><span class="p">,</span>
                      <span class="n">worker_memory</span><span class="o">=</span><span class="n">w_mem</span><span class="p">,</span>
                      <span class="n">scheduler_vcores</span><span class="o">=</span><span class="n">s_cores</span><span class="p">,</span>
                      <span class="n">scheduler_memory</span><span class="o">=</span><span class="n">s_mem</span><span class="p">,</span>
                      <span class="n">name</span><span class="o">=</span><span class="n">app_name</span><span class="p">,</span>
                      <span class="n">worker_env</span><span class="o">=</span><span class="p">{</span><span class="s1">'ARROW_LIBHDFS_DIR'</span><span class="p">:</span> <span class="n">libhdfs_env</span><span class="p">})</span>
<span class="c1"># Scale out to ten such workers</span>
<span class="n">cluster</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Connect to the cluster</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>
</pre></div>
<p>基本的连接过程如上所示，你需要安装 <code>dask-yarn</code> 模块，然后连接的时候参数</p>
<ul>
<li>environment 你的分布式应用程序的python环境包，你可以激活虚拟环境下运行 <code>venv-pack</code> 命令来打包之。</li>
<li>worker_vcores 申请分配应用资源worker cpu 核数</li>
<li>worker_memory 申请分配应用资源worker 内存数</li>
<li>scheduler_vcores 申请分配应用资源scheduler cpu 核数</li>
<li>scheduler_memory 申请分配应用资源scheduler 内存数</li>
<li>name 申请分配资源的应用名字</li>
<li>work_env 这里是大数据组配置好了hadoop的环境变量</li>
</ul>
<h3 id="worker">实际调整worker资源</h3>
<p>最开始是没有实际开启worker资源的。</p>
<div class="highlight"><pre><span></span>cluster.scale()
</pre></div>
<p>然后可以跟个数字，其会自动决定是 <code>scale_up</code> 还是 <code>scale_down</code> 。</p>
<h3 id="_2">关闭应用释放资源</h3>
<p>似乎cluster的关闭动作会申请自动释放你在hadoop集群上申请的资源，但任何非正常推荐都可能导致申请的应用资源仍占在哪里的。更保险起见是确保异常之后总能够执行:</p>
<div class="highlight"><pre><span></span>cluster.shutdown()
</pre></div>
<h3 id="_3">强制关闭某个应用</h3>
<div class="highlight"><pre><span></span> dask-yarn kill application_1538148161343_0051
</pre></div>
<h2 id="dataframe">dataframe最佳实践</h2>
<ol>
<li>如果你的机器内存够用，那么应该直接使用pandas。</li>
<li>代码在运算过程中，如果能够转到pandas，那么也应该尽早转到pandas。</li>
<li>pandas的优化：避免apply，使用向量化操作，用分类等。这些对dask的dataframe都有效。尤其是向量化的操作风格，这个初学pandas的人很容易忽视。</li>
<li>将某一列设置为索引index，某些沿着这个列的操作将会加速，比如说沿着这个列的loc，groupby，join or merge。</li>
<li>上面提到的 <code>set_index</code> 是很昂贵的操作，你需要确认这有必要，此外不要频繁这样设置索引操作，最好后面再persist 一下。</li>
<li>聪明的persist 推荐采用如下写法来节省占用内存：</li>
</ol>
<div class="highlight"><pre><span></span>df = client.persist(df)  # replace your old lazy DataFrame
</pre></div>
<ol>
<li>设置合理的分区数 分区数太大太小都不好 </li>
<li>数据存为apache parquet文件格式</li>
</ol>
<h2 id="dataframemap_partitions">dataframe的map_partitions 返回值</h2>
<p>参考了 <a href="https://stackoverflow.com/questions/40662912/python-dask-dataframe-map-partitions-return-value">这个网页</a> 。</p>
<ol>
<li>如果函数返回的标量，那么map_partitions 返回的是 dask Series object</li>
<li>如果函数返回的是pd.Series object， 那么 map_partitions 会将这些 Series 对象连接起来，返回的也是 dask Series object。</li>
<li>如果函数返回的pd.DataFrame object ，那么map_partitions 会将这些Dataframe连接起来，沿着axis=0，也就是纵向，返回的是dask DataFrame对象。</li>
</ol>
<h2 id="dask_1">dask单机版</h2>
<p>dask单机版在熟悉dask命令和基本调试代码上还是很有用的，不需要做任何配置就是dask单机版。</p>
<p>按照官方文档，单机版也分为单机调度或分布式调度两种，官方文档推荐如下采用分布式调度，说有更好的诊断功能等。</p>
<div class="highlight"><pre><span></span>from dask.distributed import Client, LocalCluster
cluster = LocalCluster()
client = Client(cluster)
</pre></div>
<p>似乎现在只能在linux上运行了。</p>
<p>单机版的线程调度中还是有所区别的：</p>
<ul>
<li>相同的进程中用多个线程 【】 默认是dask.array dask.dataframe dask.delayed</li>
</ul>
<p>scheduler="threads"</p>
<ul>
<li>分开的进程处理 默认是dask.bag</li>
</ul>
<p>scheduler="processes"</p>
<ul>
<li>单线程式</li>
</ul>
<p>scheduler="single-threaded"</p>
<h2 id="_4">参考资料</h2>
<ol>
<li><a href="https://docs.dask.org/en/latest/">dask官方文档</a></li>
</ol>

            <section>
<div class="panel-group" id="accordion2">
    <div class="panel panel-default">
        <div class="panel-heading">
            <a class="accordion-toggle disqus-comment-count" data-toggle="collapse" data-parent="#accordion2"
                href="https://a358003542.github.io/articles/dask-module.html#disqus_thread">
                Comments
            </a>
        </div>
        <div id="disqus_thread" class="panel-collapse collapse">
            <div class="panel-body">
                <div class="comments">
                    <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'cdwanzes-blog';
        var disqus_identifier = 'https://a358003542.github.io/articles/dask-module.html';
    var disqus_url = 'https://a358003542.github.io/articles/dask-module.html';

    (function() {
         var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
         dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
         (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

                </div>
            </div>
        </div>
    </div>
</div>
</section>

            <hr/>

        </div>
        <section>
        <div class="col-md-2" style="float:right;font-size:0.9em;">
            <h4>首发于：</h4>
            <time pubdate="pubdate" datetime="2019-09-22T00:00:00+08:00">2019年 9月 22日 </time>



            <h4>分类：</h4>
            <a class="category-link" href="https://a358003542.github.io/categories.html#programming-ref">programming</a>

        </div>
        </section>
</div>
</article>
    </div>
    <div class="col-md-1"></div>

</div>


<div id="push"></div>
<button id="gotop" type="button" class="btn btn-default">
    <span class="glyphicon glyphicon-arrow-up" aria-hidden="true"></span>
</button>

<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a> and updated by <a href="https://github.com/a358003542" title="wanze Home Page">wanze</a></li>
    </ul>
</div>
</footer>

        <script src="https://a358003542.github.io/theme/js/jquery.min.js"></script>
    <script src="https://a358003542.github.io/theme/js/bootstrap.min.js"></script>

    <script src="https://a358003542.github.io/theme/js/moment.min.js"></script>

    <script src="https://a358003542.github.io/theme/js/base.js"></script>

            <script type="text/javascript">
var disqus_shortname = 'cdwanzes-blog';
(function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>
<script  language="javascript" type="text/javascript">
function uncollapse() {
    if (window.location.hash.match(/^#comment-\d+$/)) {
        $('#disqus_thread').collapse('show');
    }
}
</script>
<script type="text/javascript" language="JavaScript">
uncollapse();
window.onhashchange=function(){
    if (window.location.hash.match(/^#comment-\d+$/))
        window.location.reload(true);
}
</script>
<script>
$('#disqus_thread').on('shown', function () {
    var link = document.getElementsByClassName('accordion-toggle');
    var old_innerHTML = link[0].innerHTML;
    $(link[0]).fadeOut(500, function() {
        $(this).text('Click here to hide comments').fadeIn(500);
    });
    $('#disqus_thread').on('hidden', function () {
        $(link[0]).fadeOut(500, function() {
            $(this).text(old_innerHTML).fadeIn(500);
        });
    })
})
</script>




</body>
</html>