<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="baidu-site-verification" content="D4VqC4HppC"/>
    <meta name="msvalidate.01" content="55CB117A61A6F8286173763FB18D9625"/>

        <meta name="author" content="cdwanze"/>
        <meta name="copyright" content="cdwanze"/>

        <meta property="og:type" content="article"/>
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="machine-learning, 机器学习, " />

<meta property="og:title" content="机器学习第二谈之初识多层神经网络 "/>
<meta property="og:url" content="/articles/machine-learning-talk-two.html" />
<meta property="og:description" content="前言 本文先用tensorflow来实现单层神经网络处理mnist问题，然后用keras来写一个两层神经网络来解决mnist问题。最后试着用keras编写一个简单的深度学习模型，也就是多层神经网络来解决mnist问题。 本文代码主要参考了keras的examples代码库，同时本文也考虑了一些输入数据的预处理统一化过程。 数据预处理 首先我们利用keras来下载mnist相关数据并进行必要的预处理操作。 from keras.datasets import mnist (train_images, train_labels), (test_images, test_labels) = mnist.load_data() train_images.shape (60000, 28, 28) train_labels.shape (60000,) train_images 的shape第一维度是60000，说明有6万个图片，然后标签第一维度也是6万与之对应。 train_images = train_images.reshape((60000, 784)) train_images = train_images.astype(&#39;float32&#39;) train_images = train_images / 255 第一步将第二维第三维数据合并到一维。 第二步是转换ndarray的dtype数据类型。 第三部是将数据0-255 归一化为 0- 1 …" />
<meta property="og:site_name" content="cdwanze的博文" />
<meta property="og:article:author" content="cdwanze" />
<meta property="og:article:published_time" content="2018-11-05T00:00:00+08:00" />
<meta property="" content="2018-11-05T00:00:00+08:00" />
<meta name="twitter:title" content="机器学习第二谈之初识多层神经网络 ">
<meta name="twitter:description" content="前言 本文先用tensorflow来实现单层神经网络处理mnist问题，然后用keras来写一个两层神经网络来解决mnist问题。最后试着用keras编写一个简单的深度学习模型，也就是多层神经网络来解决mnist问题。 本文代码主要参考了keras的examples代码库，同时本文也考虑了一些输入数据的预处理统一化过程。 数据预处理 首先我们利用keras来下载mnist相关数据并进行必要的预处理操作。 from keras.datasets import mnist (train_images, train_labels), (test_images, test_labels) = mnist.load_data() train_images.shape (60000, 28, 28) train_labels.shape (60000,) train_images 的shape第一维度是60000，说明有6万个图片，然后标签第一维度也是6万与之对应。 train_images = train_images.reshape((60000, 784)) train_images = train_images.astype(&#39;float32&#39;) train_images = train_images / 255 第一步将第二维第三维数据合并到一维。 第二步是转换ndarray的dtype数据类型。 第三部是将数据0-255 归一化为 0- 1 …">

    <title>
机器学习第二谈之初识多层神经网络  · cdwanze的博文
</title>


        <link href="/theme/css/font-awesome.css" rel="stylesheet"
              media="screen">
        <link href="/theme/css/bootstrap.min.css" rel="stylesheet"
              media="screen">

            <link rel="stylesheet" type="text/css"
                  href="/theme/css/pygments.css" media="screen">
            <link rel="stylesheet" type="text/css"
                  href="/theme/css/elegant.css" media="screen">
            <link rel="stylesheet" type="text/css"
                  href="/theme/css/custom.css" media="screen">






</head>
<body>

<nav class="navbar">
    <div class="navbar navbar-default" role="navigation">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed"
                    data-toggle="collapse" data-target=".navbar-collapse"
                    aria-expanded="false">
                <span class="sr-only">Navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <a class="navbar-brand" href="/"><span
                    class=site-name>网站首页</span></a>
        </div>


        <div class="navbar-collapse collapse">
            <form action="/search.html"
                  onsubmit="return validateForm(this.elements['q'].value);"
                  class="navbar-form navbar-left">
                <div class="form-group">
                    <input type="text" name="q" id="tipue_search_input"
                           class="form-control" placeholder="Search..."
                           style="width:430px;">
                </div>
                <button class="btn btn-default" type="submit">搜索</button>
            </form>


            <ul class="nav navbar-nav nav-pills navbar-right">
                <li >
                    <a href="">博文首页</a></li>

                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle"
                           data-toggle="dropdown" role="button"
                           aria-haspopup="true" aria-expanded="false">查找文章<span
                                class="caret"></span></a>
                        <ul class="dropdown-menu">
                            <li><a class="slowscroll" href="/categories.html">按分类</a>
                            </li>
                            <li><a class="slowscroll" href="/tags.html">按标签</a>
                            </li>
                        </ul>
                    </li>


                        <li >
                            <a href="/guan-yu-ben-wang-zhan.html">关于本网站</a>
                        </li>
                        <li >
                            <a href="/gong-gao.html">公告</a>
                        </li>
            </ul>


        </div>
    </div>
</nav>


<div class="container-fluid">
    <div class="col-md-1 col-md-1-left"></div>
    <div class="col-md-10">
<article>
<div class="row">
    <header class="page-header col-md-10 col-md-offset-2">
    <h1><a href="/articles/machine-learning-talk-two.html"> 机器学习第二谈之初识多层神经网络  </a></h1>
    </header>
</div>

<div class="row">
    <div class="col-md-2 table-of-content">
        <nav>
        <h4>目录</h4>
        <div class="toc">
<ul>
<li><a href="#_1">前言</a></li>
<li><a href="#_2">数据预处理</a></li>
<li><a href="#_3">感知器</a><ul>
<li><a href="#_4">交叉熵</a></li>
<li><a href="#tensorflow">使用tensorflow自带的交叉熵方法</a></li>
</ul>
</li>
<li><a href="#_5">多层感知器</a><ul>
<li><a href="#_6">准备数据</a></li>
<li><a href="#_7">建模</a></li>
</ul>
</li>
<li><a href="#_8">多层神经网络或者深度学习</a><ul>
<li><a href="#_9">保存模型</a></li>
</ul>
</li>
<li><a href="#_10">参考资料</a></li>
</ul>
</div>
        </nav>
    </div>
    <div class="col-md-8 article-content">

            
            
<h2 id="_1">前言</h2>
<p>本文先用tensorflow来实现单层神经网络处理mnist问题，然后用keras来写一个两层神经网络来解决mnist问题。最后试着用keras编写一个简单的深度学习模型，也就是多层神经网络来解决mnist问题。</p>
<p>本文代码主要参考了keras的examples代码库，同时本文也考虑了一些输入数据的预处理统一化过程。</p>
<h2 id="_2">数据预处理</h2>
<p>首先我们利用keras来下载mnist相关数据并进行必要的预处理操作。</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>
<div class="highlight"><pre><span></span>train_images.shape
(60000, 28, 28)
train_labels.shape
(60000,)
</pre></div>
<p>train_images 的shape第一维度是60000，说明有6万个图片，然后标签第一维度也是6万与之对应。</p>
<div class="highlight"><pre><span></span><span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span> <span class="o">/</span> <span class="mi">255</span>
</pre></div>
<p>第一步将第二维第三维数据合并到一维。</p>
<p>第二步是转换ndarray的dtype数据类型。</p>
<p>第三部是将数据0-255 归一化为 0- 1 。</p>
<p>类似的test_images也需要这样处理，这里就略过了。</p>
<p>标签数据需要进行one-hot编码处理：</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="n">train_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
<p>one-hot编码的具体解释这里略过了，其他地方会讨论的。</p>
<h2 id="_3">感知器</h2>
<p>感知器就是一层或者说单层神经网络。感知器类似于逻辑回归模型，只能做线性分类任务。</p>
<p>单层神经网络的编写用Keras非常的简单，但如果用tensorflow还是需要写一些代码的。不过作为一开始推荐还是用tensorflow来写一个简单的单层神经网络。因为Keras是基于tensorflow的更高层模块，这对于我们理解Keras具体做了什么工作很有帮助，也能帮助我们理解具体单层神经网络进行了那些数学运算。</p>
<div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]))</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">y_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">y_logits</span> <span class="p">)</span>
</pre></div>
<p><img alt="img" src="/images/机器学习/单层神经网络数学运算.png" title="单层神经网络数学运算"/></p>
<p>输入参数x第二维度784对应权重矩阵第一维度784，通常神经网络权重矩阵W的shape是(前一层节点数, 后一层节点数) 。这样输入参数矩阵x和权重矩阵W进行矩阵乘法【张量的点积，np.dot运算】之后得到第二维度等于权重矩阵第二维度的矩阵。输出的值数据送入 y_logits。这里 <code>tf.matmul</code> 就是进行的矩阵的乘法运算。</p>
<p>这里 <code>tf.nn.softmax</code> 是激活函数，具体softmax激活函数的讨论这里略过了。</p>
<h3 id="_4">交叉熵</h3>
<p>tensorflow提供了专门的交叉熵计算函数，这里我们先用更原始的计算公式来看一下（参考了 <a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_beginners.html">这篇文章</a> ）：</p>
<div class="highlight"><pre><span></span><span class="n">cross_entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">y_true</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_pred</span><span class="p">))</span>
</pre></div>
<p>大体过程如下所示：
</p>
<div class="math">$$
- \sum (1,0,0) * log((0.5,0.4,0.1)) = -(1*log0.5 + 0*log0.4 + 0*log0.1) = 0.301
$$</div>
<p>
交叉熵越大那么预测值越偏离真实值，交叉熵越小那么预测值越接近真实值。</p>
<div class="highlight"><pre><span></span><span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">)</span> <span class="c1"># 0.01是学习速率</span>
</pre></div>
<h3 id="tensorflow">使用tensorflow自带的交叉熵方法</h3>
<p>推荐使用tensorflow自带的softmax+交叉熵方法来计算交叉熵，参考了 <a href="http://blog.csdn.net/behamcheung/article/details/71911133">这篇文章</a> ，说是计算会更稳定些。</p>
<p>现在让我们把到目前的代码整理一下：</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span> <span class="o">/</span> <span class="mi">255</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]))</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">y_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">y_logits</span> <span class="p">)</span>
<span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">y_logits</span> <span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_true</span><span class="p">))</span>
<span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">)</span>
</pre></div>
<p>好了，我们的例子进入收尾阶段了：</p>
<div class="highlight"><pre><span></span><span class="n">correct_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_mask</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> 
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

    <span class="c1"># Train</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
        <span class="n">batch_xs</span> <span class="o">=</span> <span class="n">train_images</span><span class="p">[</span><span class="n">count</span><span class="o">*</span><span class="mi">128</span><span class="p">:</span><span class="mi">128</span><span class="o">*</span><span class="p">(</span><span class="n">count</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
        <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[</span><span class="n">count</span><span class="o">*</span><span class="mi">128</span><span class="p">:</span><span class="mi">128</span><span class="o">*</span><span class="p">(</span><span class="n">count</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">batch_xs</span><span class="p">,</span> <span class="n">y_true</span><span class="p">:</span> <span class="n">batch_ys</span><span class="p">})</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">count</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">ans</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">y_true</span><span class="p">:</span> <span class="n">test_labels</span><span class="p">})</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">"Accuracy: {:.4}%"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ans</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
    <span class="c1"># LAST</span>
    <span class="n">ans</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">y_true</span><span class="p">:</span> <span class="n">test_labels</span><span class="p">})</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"Accuracy: {:.4}%"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ans</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
<p>关于tf.argmax 函数请看下面的例子。不感兴趣的可以略过，其作用就是把标签解释出来，不是这里的重点。</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">stddev</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span> <span class="p">)</span>

<span class="o">-----</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">0.0919205</span> <span class="p">,</span>  <span class="mf">0.06030607</span><span class="p">,</span>  <span class="mf">0.01196606</span><span class="p">,</span>  <span class="mf">0.03031359</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.13546242</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.12748787</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.09680127</span><span class="p">,</span>  <span class="mf">0.12220833</span><span class="p">,</span>  <span class="mf">0.15264732</span><span class="p">,</span>  <span class="mf">0.05449662</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.01277541</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00535311</span><span class="p">,</span>  <span class="mf">0.03589706</span><span class="p">,</span>  <span class="mf">0.01658093</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.16726552</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.06979545</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14876817</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.03735523</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0439501</span> <span class="p">,</span>  <span class="mf">0.15896702</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">0.05869294</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14986654</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.17551927</span><span class="p">,</span>  <span class="mf">0.08360171</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00648978</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.03274798</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05770732</span><span class="p">,</span>  <span class="mf">0.01505487</span><span class="p">,</span>  <span class="mf">0.13726853</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01670119</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">0.02666636</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05316785</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05433881</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.02210794</span><span class="p">,</span>  <span class="mf">0.01175172</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.0674843</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.06402522</span><span class="p">,</span>  <span class="mf">0.00812987</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.17738222</span><span class="p">,</span>  <span class="mf">0.01375954</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">0.01734987</span><span class="p">,</span>  <span class="mf">0.01096244</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.19889738</span><span class="p">,</span>  <span class="mf">0.08350741</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00222254</span><span class="p">,</span>
         <span class="mf">0.05094135</span><span class="p">,</span>  <span class="mf">0.06777989</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01986633</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1863249</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.04648132</span><span class="p">]],</span>
      <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
<span class="o">---</span>

<span class="n">col_max</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="p">)</span>
<span class="o">----</span>
<span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int64</span><span class="p">)</span>
<span class="o">---</span>
<span class="n">row_max</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span> 
<span class="o">---</span>
<span class="n">array</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int64</span><span class="p">)</span>
<span class="o">---</span>
</pre></div>
<p>所以 tf.argmax 第二个参数是1，那么返回一行数值最大的那个index索引值。 <code>tf.argmax(y_pred, 1)</code> 返回的那个索引值在本例中比较简单，就是实际预测的数字值。</p>
<p>tf.reduce_mean 将所有维度的元素相加然后求平均值</p>
<p>这个例子最后就是调用tensorflow的作业流程，启动运算数据流。然后评估一下对于测试数据现在精度如何了。这些不是这里的重点。就单层神经网络来说mnist例子很难超过90%的。</p>
<h2 id="_5">多层感知器</h2>
<p>多层感知器实际上就是两层全连接神经网络。理论上两层神经网络可以无限逼近任意连续的函数了。下面用Keras来实现一个多层感知器。</p>
<p>首先我们试着把上面单层神经网络用Keras写一遍，下面是准备数据过程，后面都一样的。</p>
<h3 id="_6">准备数据</h3>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span> <span class="o">/</span> <span class="mi">255</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>
</pre></div>
<h3 id="_7">建模</h3>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
</pre></div>
<div class="highlight"><pre><span></span>Epoch 1/5
60000/60000 [==============================] - 1s 13us/step - loss: 0.6063 - acc: 0.8482
Epoch 2/5
60000/60000 [==============================] - 1s 12us/step - loss: 0.3316 - acc: 0.9083
Epoch 3/5
60000/60000 [==============================] - 1s 12us/step - loss: 0.3025 - acc: 0.9159
Epoch 4/5
60000/60000 [==============================] - 1s 11us/step - loss: 0.2889 - acc: 0.9194
Epoch 5/5
60000/60000 [==============================] - 1s 12us/step - loss: 0.2806 - acc: 0.9219
</pre></div>
<div class="highlight"><pre><span></span>score = model.evaluate(test_images, test_labels, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
</pre></div>
<div class="highlight"><pre><span></span>Test loss: 0.2757013351589441
Test accuracy: 0.9232
</pre></div>
<p>结果大概也是差不多的。因为这个例子多运行几次epoch，但单层神经网络再怎么优化也只能到92%了。</p>
<p>上面的建模过程稍微加一行，我们就构建了一个多层感知器。一般多层神经网络前面的激活函数选relu会更好一些。也就多加了一层，最后输出节点数为10的神经网络。</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
</pre></div>
<div class="highlight"><pre><span></span>Epoch 1/5
60000/60000 [==============================] - 5s 85us/step - loss: 0.2569 - acc: 0.9258
Epoch 2/5
60000/60000 [==============================] - 5s 84us/step - loss: 0.1037 - acc: 0.9688
Epoch 3/5
60000/60000 [==============================] - 5s 87us/step - loss: 0.0685 - acc: 0.9790
Epoch 4/5
60000/60000 [==============================] - 5s 85us/step - loss: 0.0508 - acc: 0.9848
Epoch 5/5
60000/60000 [==============================] - 5s 87us/step - loss: 0.0368 - acc: 0.9888
</pre></div>
<div class="highlight"><pre><span></span>Test loss: 0.07560657636675751
Test accuracy: 0.9777
</pre></div>
<p>精度能够到97%了。</p>
<p>下面是Keras代码库examples里面的解决mnist问题的多层感知器，我根据上面的讨论将代码稍微调整下，建模过程如下：</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span><span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">RMSprop</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
<p>区别就是又加了一层神经网络。</p>
<div class="highlight"><pre><span></span>Epoch 1/5
60000/60000 [==============================] - 8s 139us/step - loss: 0.2197 - acc: 0.9320
Epoch 2/5
60000/60000 [==============================] - 8s 140us/step - loss: 0.0815 - acc: 0.9750
Epoch 3/5
60000/60000 [==============================] - 9s 145us/step - loss: 0.0530 - acc: 0.9836
Epoch 4/5
60000/60000 [==============================] - 9s 151us/step - loss: 0.0374 - acc: 0.9886
Epoch 5/5
60000/60000 [==============================] - 9s 151us/step - loss: 0.0302 - acc: 0.9899
</pre></div>
<div class="highlight"><pre><span></span>Test loss: 0.08149926771794035
Test accuracy: 0.9808
</pre></div>
<p>examples里面还新加入了Dropout层，这个是一种过拟合技术，我们加上之后会如何：</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span><span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">RMSprop</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
<div class="highlight"><pre><span></span>Epoch 1/5
60000/60000 [==============================] - 10s 162us/step - loss: 0.2439 - acc: 0.9253
Epoch 2/5
60000/60000 [==============================] - 10s 169us/step - loss: 0.1031 - acc: 0.9688
Epoch 3/5
60000/60000 [==============================] - 9s 151us/step - loss: 0.0760 - acc: 0.9771
Epoch 4/5
60000/60000 [==============================] - 10s 165us/step - loss: 0.0604 - acc: 0.9817
Epoch 5/5
60000/60000 [==============================] - 9s 155us/step - loss: 0.0512 - acc: 0.9846
</pre></div>
<div class="highlight"><pre><span></span>Test loss: 0.07319687194137806
Test accuracy: 0.9814
</pre></div>
<p>区别其实不大，至少就mnist来说提升最大的是又新加入了一层神经网络，加入Dropout层没看出区别。</p>
<h2 id="_8">多层神经网络或者深度学习</h2>
<p>卷积神经网络相关后面的讨论补上，这里我们主要来看下Keras代码库examples里面介绍的用CNN，深度学习神经网络来解决mnist问题效果如何。具体理解后面再说。</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span> <span class="o">==</span> <span class="s1">'channels_first'</span><span class="p">:</span>
    <span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
    <span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
<p>这里似乎涉及到不同backend的图形维度选择问题，这个后面再说。</p>
<div class="highlight"><pre><span></span><span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span> <span class="o">/</span> <span class="mi">255</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>
</pre></div>
<p>继续之前的数据预处理。</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adadelta</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
<p>本例子跑起来开始有点慢了。Dropout应该不算一层，Flatten我估计不算一层，那么上面例子大概有5层。</p>
<div class="highlight"><pre><span></span>Epoch 1/5
60000/60000 [==============================] - ETA: 0s - loss: 0.2683 - acc: 0.917 - 119s 2ms/step - loss: 0.2683 - acc: 0.9173
Epoch 2/5
60000/60000 [==============================] - 120s 2ms/step - loss: 0.0891 - acc: 0.9734
Epoch 3/5
60000/60000 [==============================] - 115s 2ms/step - loss: 0.0655 - acc: 0.9804
Epoch 4/5
60000/60000 [==============================] - 111s 2ms/step - loss: 0.0555 - acc: 0.9833
Epoch 5/5
60000/60000 [==============================] - 114s 2ms/step - loss: 0.0466 - acc: 0.9856
</pre></div>
<div class="highlight"><pre><span></span>Test loss: 0.031076731445921907
Test accuracy: 0.9898
</pre></div>
<p>例子报道说epochs=12的时候精度能够上升到99%。</p>
<p>为了公平起见，绝对多层感知器和CNN神经网络这两个例子都按照epochs=12再跑一次来对比一下看看。</p>
<p>多层感知器：</p>
<div class="highlight"><pre><span></span>Test loss: 0.08958661408673184
Test accuracy: 0.9821
</pre></div>
<p>和跑5次没有区别了。</p>
<p>CNN的看了一下个人PC CPU基本上跑满了，然后GPU没怎么用，tensorflow决定换成tensorflow-gpu 【PS：注意之前你用pip安装tensorflow了的，再安装个tensorflow-gpu即可，原来那个tensorflow包不能删的。】然后再看下。然后发现我这里显卡写着Intel UHD，似乎只有NAVID才能开启gpu，算了。</p>
<p>CNN神经网络：</p>
<div class="highlight"><pre><span></span>Test loss: 0.028602463609369078
Test accuracy: 0.992
</pre></div>
<p>精度提升到了99%，看来CNN多训练几次后续效果还能提升，别小看了这1%的提升啊！</p>
<h3 id="_9">保存模型</h3>
<p>一次训练有点费时了，那么如何保存训练好的模型呢？这个问题在keras文档FAQ里面有，算是很经典的一个问题了。</p>
<div class="highlight"><pre><span></span>model.save('my_model.h5')
</pre></div>
<p>保存的数据有：</p>
<ul>
<li>模型的结构，方便重新创造模型</li>
<li>模型训练得到的权重数据</li>
<li>训练损失和优化器配置</li>
<li>优化器状态，允许继续上一次训练</li>
</ul>
<p>下次使用模型如下所示：</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span> <span class="o">==</span> <span class="s1">'channels_first'</span><span class="p">:</span>
    <span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>


<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span> <span class="o">/</span> <span class="mi">255</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>
</pre></div>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">'cnn_for_mnist_model.h5'</span><span class="p">)</span>
</pre></div>
<div class="highlight"><pre><span></span>score = model.evaluate(test_images, test_labels, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
</pre></div>
<div class="highlight"><pre><span></span>Test loss: 0.028602463609369078
Test accuracy: 0.992
</pre></div>
<h2 id="_10">参考资料</h2>
<ol>
<li>机器学习实战 Peter Harrington 著 李锐 李鹏等译</li>
<li><a href="http://ml.apachecn.org/mlia/">机器学习实战线上教程</a></li>
<li>python深度学习 弗朗索瓦·肖奈</li>
<li><a href="https://github.com/exacity/deeplearningbook-chinese">deep learning 中文版</a></li>
<li>机器学习 周志华著</li>
<li><a href="https://www.cnblogs.com/subconscious/p/5058741.html">这个文章介绍神经网络写的很好</a></li>
</ol>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            
            
            <hr/>

        </div>
        <section>
        <div class="col-md-2" style="float:right;font-size:0.9em;">
            <h4>首发于：</h4>
            <time pubdate="pubdate" datetime="2018-11-05T00:00:00+08:00">2018年 11月 5日 </time>

<h4>最近更新于：</h4>
<time datetime="2018-11-05T00:00:00+08:00">2018年 11月 5日 </time>

            <h4>分类：</h4>
            <a class="category-link" href="/categories.html#ji-qi-xue-xi-ref">机器学习</a>
            <h4>标签：</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="/tags.html#machine-learning-ref">machine-learning
                    <span>8</span>
</a></li>
            </ul>
        </div>
        </section>
</div>
</article>
    </div>
    <div class="col-md-1"></div>

</div>


<div id="push"></div>


<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a> and updated by <a href="http://www.cdwanze.work" title="cdwanze Home Page">cdwanze</a></li>
    </ul>
</div>
</footer>

        <script src="/theme/js/jquery.min.js"></script>
    <script src="/theme/js/bootstrap.min.js"></script>
    <script>
        function validateForm(query) {
            return (query.length > 0);
        }
    </script>

    <script>
        function adjust_search_width() {
            var w = document.documentElement.clientWidth;
            if ((w > 755) && (w < 975)) {
                plus_width = w - 755;
                $('.navbar-form .form-control').outerWidth(210 + plus_width);
            } else if (w >= 975) {
                $('.navbar-form .form-control').outerWidth(210 + 220);
            } else if (w <= 755) {
                $('.navbar-form .form-control').css('width', '100%')
            }
        }

        $(document).ready(function () {
            adjust_search_width();
        });

        window.onresize = function () {
            adjust_search_width();
        }

    </script>


    



</body>
</html>