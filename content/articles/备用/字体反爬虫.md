Slug: zi-ti-fan-pa-chong
Date: 20190908

在爬虫的时候，你分析网页会看到，某些东西看上去是乱码，其css设置了一种额外的字体。怎么破解里面的内容呢？

首先你需要把目标字体下载下来，通常这种字体有各种各样的名字，里面的具体字体codepoint也是随机的...

如果你下载一个fontcreator会看到具体哪个字对应哪个codepoint，而爬虫这边编码，我们需要使用python的 fonttools库来加载字体。

首先你需要下载好字体，保存好字体做好缓存工作。

见本文的参考资料2，然后就是利用 fonttools 模块加载目标字体。

```
font = TTFont(font_filename)
```

然后就是分析这个字体的cmap tables的cmap数据，不同的字体似乎情况不同，这个要实际分析，由于fonttools这个模块文档较少，加上我对字体知识不太多，所以只能简单摸索下了。

```
font_mapping = font['cmap'].tables[?].cmap
```

如果你找到 font_mapping 了，字符 用python的 ord 函数处理下，就能得到目标字符的 unicode code point，也就是我们上面说的字体的code point，在这个 font_mapping 里面你会看到的，然后具体什么内容就出来了。



## 参考资料

1. https://zhuanlan.zhihu.com/p/32087297
2. [how to find out which codepoint in ttf file](https://unix.stackexchange.com/questions/247108/how-to-find-out-which-unicode-codepoints-are-defined-in-a-ttf-file)